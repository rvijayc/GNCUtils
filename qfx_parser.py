#!/usr/bin/env python3
"""
QFX Parser and Transaction Categorizer
Parses QFX files and applies categorization rules generated by analyze_transactions.py
"""

import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from collections import defaultdict, Counter
from typing import List, Dict, Optional, Tuple
import re

from rich.console import Console
from rich.table import Table
import IPython

try:
    import ofxparse
except ImportError:
    print("Error: ofxparse library not found.")
    print("Install with: pip install ofxparse")
    sys.exit(1)

try:
    from tabulate import tabulate
except ImportError:
    print("Error: tabulate library not found.")
    print("Install with: pip install tabulate")
    sys.exit(1)


class QFXParser:
    """Parses QFX files and categorizes transactions using existing rules."""
    
    def __init__(self, qfx_file_path: str, rules_file_path: Optional[str] = None):
        self.qfx_file_path = qfx_file_path
        self.rules_file_path = rules_file_path or 'categorization_rules.json'
        self.transactions = []
        self.rules = []
        self.categorized_transactions = []
        self.uncategorized_transactions = []
        self.low_confidence_transactions = []
        
    def load_rules(self) -> bool:
        """Load categorization rules from JSON file."""
        try:
            if not Path(self.rules_file_path).exists():
                print(f"Warning: Rules file not found: {self.rules_file_path}")
                print("Run analyze_transactions.py first to generate categorization rules.")
                return False
                
            with open(self.rules_file_path, 'r') as f:
                rules_data = json.load(f)
            
            self.rules = rules_data.get('rules', [])
            print(f"Loaded {len(self.rules)} categorization rules from {self.rules_file_path}")
            return True
            
        except Exception as e:
            print(f"Error loading rules: {e}")
            return False
    
    def parse_qfx_file(self) -> bool:
        """Parse the QFX file and extract transaction data."""
        try:
            if not Path(self.qfx_file_path).exists():
                print(f"Error: QFX file not found: {self.qfx_file_path}")
                return False
            
            print(f"Parsing QFX file: {self.qfx_file_path}")
            
            with open(self.qfx_file_path, 'rb') as f:
                ofx = ofxparse.OfxParser.parse(f)
            
            # Extract account information
            if hasattr(ofx, 'account') and ofx.account:
                account = ofx.account
                account_id = getattr(account, 'account_id', 'Unknown')
                account_type = getattr(account, 'account_type', 'Unknown')
                
                print(f"Account ID: {account_id}")
                print(f"Account Type: {account_type}")
                
                # Extract transactions
                transactions = []
                for transaction in account.statement.transactions:
                    trans_data = {
                        'id': getattr(transaction, 'id', ''),
                        'date': transaction.date.strftime('%Y-%m-%d') if transaction.date else '',
                        'description': getattr(transaction, 'payee', '') or getattr(transaction, 'memo', ''),
                        'memo': getattr(transaction, 'memo', ''),
                        'amount': float(transaction.amount) if transaction.amount else 0.0,
                        'type': getattr(transaction, 'type', ''),
                        'account_id': account_id,
                        'fitid': getattr(transaction, 'id', ''),
                        'raw_description': getattr(transaction, 'payee', '') or getattr(transaction, 'memo', '')
                    }
                    transactions.append(trans_data)
                
                self.transactions = transactions
                print(f"Extracted {len(transactions)} transactions")
                
                # Print transaction date range
                if transactions:
                    dates = [t['date'] for t in transactions if t['date']]
                    if dates:
                        dates.sort()
                        print(f"Transaction date range: {dates[0]} to {dates[-1]}")
                
                return True
            else:
                print("Error: No account data found in QFX file")
                return False
                
        except Exception as e:
            print(f"Error parsing QFX file: {e}")
            return False

    def normalize_transaction_description(self, desc: str) -> Tuple[str, List[str]]:
        """
        Normalize a transaction description into two fields:
          - merchant_core: cleaned merchant string (uppercased, no long digit runs, no stray dashes)
          - numbers: list of digit sequences (3+ digits, e.g. phone numbers, IDs)
        """
        # Basic cleanup
        desc = desc.strip().upper()
        desc = re.sub(r"\s+", " ", desc)
        desc = re.sub(r"\*+", "*", desc)

        # --- Dash cleanup (order matters) ---
        # 1) Dash runs followed by digits: keep digits, drop dashes
        desc = re.sub(r"-{2,}\s*(\d+)", r" \1", desc)

        # 2) Remove dash runs not followed by digits
        desc = re.sub(r"\s*-{2,}\s*", " ", desc)

        # 3) Remove standalone/dangling hyphens (tokens ending with or equal to "-")
        desc = re.sub(r"\s-\s", " ", desc)     # "WORD - WORD" -> "WORD WORD"
        desc = re.sub(r"\s-\s*$", " ", desc)   # trailing " -"
        desc = re.sub(r"\s-$", "", desc)       # end-of-string " -"

        # 4) Preserve in-word hyphens (WAL-MART, ON-LINE), but strip stray leading/trailing
        desc = re.sub(r"(?<![A-Z0-9])-(?=[A-Z0-9])", " ", desc)   # leading "-WORD"
        desc = re.sub(r"(?<=[A-Z0-9])-(?![A-Z0-9])", " ", desc)   # trailing "WORD-"

        # Extract and remove digit sequences (3+ digits) in one pass
        numbers: List[str] = []
        def _collect_and_remove(m: re.Match) -> str:
            numbers.append(m.group(0))
            return ""

        merchant_core = re.sub(r"\d{3,}", _collect_and_remove, desc).strip()

        # Remove dangling 1â€“2 digit tokens at the end
        merchant_core = re.sub(r"\s\d{1,2}$", "", merchant_core)

        # Final space normalization
        merchant_core = re.sub(r"\s+", " ", merchant_core).strip()

        # return lower case descriptions.
        return merchant_core.lower(), numbers

    def display_transactions(self) -> None:
        """
        Display a list of transaction dicts as a Rich table.
        Only shows: date, description, amount, type, raw_description, memo.
        """
        console = Console()
        table = Table(show_header=True, header_style="bold magenta")

        # Define the columns in the desired order
        columns = ["date", "description", "amount", "type", "raw_description"]
        for col in columns:
            table.add_column(col, overflow="fold")

        # Add rows
        for tx in self.transactions:
            row = [str(tx.get(col, "")) for col in columns]
            table.add_row(*row)

        console.print(table)

    def clean_description(self, desc: str):
        prev = None
        while desc != prev:
            prev = desc
            desc, _ = self.normalize_transaction_description(desc)
        return desc

    def normalize_transaction(self, tx: Dict) -> Dict:
        """
        Given a transaction dict from your QFX parser,
        update the 'description' field with the normalized merchant_core,
        and add a new 'numbers' field with extracted digit sequences.
        """
        tx["description"] = self.clean_description(tx.get("description", ""))
        return tx

    def normalize(self):

        for t in self.transactions:
            self.normalize_transaction(t)

    def extract_merchant_name(self, description: str) -> str:
        """Extract and normalize merchant name from transaction description."""
        patterns = [
            r'PAYPAL \*([^0-9\s]+)',                    # PayPal transactions
            r'SQ \*([^0-9\s]+)',                       # Square transactions  
            r'TST\* ([^0-9\s]+)',                      # Toast/other POS
            r'AMZN MKTP ([^0-9\s]+)',                  # Amazon Marketplace
            r'UBER\s*([^0-9\s]*)',                     # Uber services
            r'LYFT\s*([^0-9\s]*)',                     # Lyft services
            r'SPOTIFY\s*([^0-9\s]*)',                  # Spotify
            r'NETFLIX\s*([^0-9\s]*)',                  # Netflix
            r'([A-Z][A-Z0-9\s&]+?)(?:\s+\d|\s*$)',     # General merchant pattern
        ]
        
        description_clean = description.upper().strip()
        
        for pattern in patterns:
            match = re.search(pattern, description_clean)
            if match:
                merchant = match.group(1).strip() if match.group(1) else match.group(0)
                # Clean up common artifacts
                merchant = re.sub(r'\s+', ' ', merchant)
                merchant = re.sub(r'[^A-Z0-9\s&]', '', merchant)
                merchant = merchant.strip()
                if len(merchant) > 2:
                    return merchant
        
        # Fallback: first few words as merchant name
        words = description_clean.split()
        merchant_words = []
        for word in words[:4]:  # Take up to 4 words
            if len(word) > 2 and not re.match(r'^\d+$', word):  # Skip short words and pure numbers
                merchant_words.append(word)
            if len(merchant_words) >= 2:  # Stop after getting 2 good words
                break
                
        return ' '.join(merchant_words) if merchant_words else description_clean[:20]
    
    def similarity_ratio(self, a: str, b: str) -> float:
        """Calculate similarity ratio between two strings."""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, a.lower(), b.lower()).ratio()
    
    def apply_rule(self, transaction: Dict, rule: Dict) -> Tuple[bool, float]:
        """Apply a single rule to a transaction and return (matched, confidence)."""
        rule_type = rule['type']
        pattern = rule['pattern']
        description = transaction['description']
        
        if rule_type == 'merchant_name':
            merchant = self.extract_merchant_name(description)
            if merchant.lower() == pattern.lower():
                return True, rule['confidence']
                
        elif rule_type == 'fuzzy_merchant':
            merchant = self.extract_merchant_name(description)
            # Check if merchant matches any variant
            variants = rule.get('variants', [pattern])
            for variant in variants:
                if self.similarity_ratio(merchant, variant) >= 0.8:
                    return True, rule['confidence']
                    
        elif rule_type == 'description_contains':
            cleaned_desc = self.clean_description(description)
            if pattern.lower() in cleaned_desc:
                return True, rule['confidence']
                
        elif rule_type == 'description_exact':
            cleaned_desc = self.clean_description(description)
            if cleaned_desc == pattern.lower():
                return True, rule['confidence']
        
        return False, 0.0
    
    def categorize_transactions(self, confidence_threshold: float = 0.3) -> None:
        """Categorize transactions using the loaded rules."""
        if not self.rules:
            print("No rules loaded. All transactions will be uncategorized.")
            self.uncategorized_transactions = self.transactions.copy()
            return
        
        categorized = []
        uncategorized = []
        low_confidence = []
        
        print(f"Categorizing {len(self.transactions)} transactions...")
        print(f"Using confidence threshold: {confidence_threshold}")
        
        for transaction in self.transactions:
            best_match = None
            best_confidence = 0.0
            
            # Try each rule
            for rule in self.rules:
                matched, confidence = self.apply_rule(transaction, rule)
                if matched and confidence > best_confidence:
                    best_match = rule
                    best_confidence = confidence
            
            # Categorize based on best match
            if best_match:
                categorized_transaction = transaction.copy()
                categorized_transaction.update({
                    'predicted_category': best_match['category'],
                    'rule_type': best_match['type'],
                    'rule_pattern': best_match['pattern'],
                    'confidence': best_confidence,
                    'rule_transaction_count': best_match.get('transaction_count', 0)
                })
                
                if best_confidence >= confidence_threshold:
                    categorized.append(categorized_transaction)
                else:
                    low_confidence.append(categorized_transaction)
            else:
                uncategorized.append(transaction)
        
        self.categorized_transactions = categorized
        self.uncategorized_transactions = uncategorized
        self.low_confidence_transactions = low_confidence
        
        print(f"Categorization complete:")
        print(f"  Categorized: {len(categorized)} transactions")
        print(f"  Low confidence: {len(low_confidence)} transactions")
        print(f"  Uncategorized: {len(uncategorized)} transactions")
    
    def generate_summary(self) -> Dict:
        """Generate a comprehensive summary of parsed and categorized transactions."""
        total_transactions = len(self.transactions)
        total_amount = sum(t['amount'] for t in self.transactions)
        
        # Category summaries
        category_summary = defaultdict(lambda: {'count': 0, 'amount': 0.0, 'avg_confidence': 0.0})
        
        for trans in self.categorized_transactions + self.low_confidence_transactions:
            category = trans.get('predicted_category', 'Unknown')
            category_summary[category]['count'] += 1
            category_summary[category]['amount'] += trans['amount']
            if 'confidence' in trans:
                category_summary[category]['avg_confidence'] += trans['confidence']
        
        # Calculate average confidence per category
        for category_data in category_summary.values():
            if category_data['count'] > 0:
                category_data['avg_confidence'] /= category_data['count']
        
        # Transaction type summary
        transaction_types = Counter(t['type'] for t in self.transactions if t.get('type'))
        
        # Date range
        dates = [t['date'] for t in self.transactions if t['date']]
        date_range = {'start': min(dates), 'end': max(dates)} if dates else {'start': None, 'end': None}
        
        # Merchant analysis for uncategorized transactions
        uncategorized_merchants = Counter()
        for trans in self.uncategorized_transactions:
            merchant = self.extract_merchant_name(trans['description'])
            if merchant:
                uncategorized_merchants[merchant] += 1
        
        summary = {
            'file_info': {
                'qfx_file': self.qfx_file_path,
                'rules_file': self.rules_file_path,
                'parsed_at': datetime.now().isoformat()
            },
            'transaction_counts': {
                'total': total_transactions,
                'categorized': len(self.categorized_transactions),
                'low_confidence': len(self.low_confidence_transactions),
                'uncategorized': len(self.uncategorized_transactions)
            },
            'financial_summary': {
                'total_amount': total_amount,
                'average_transaction': total_amount / total_transactions if total_transactions > 0 else 0,
                'date_range': date_range
            },
            'transaction_types': dict(transaction_types),
            'category_breakdown': dict(category_summary),
            'needs_attention': {
                'uncategorized_merchants': dict(uncategorized_merchants.most_common(10)),
                'low_confidence_count': len(self.low_confidence_transactions),
                'uncategorized_count': len(self.uncategorized_transactions)
            }
        }
        
        return summary
    
    def print_summary(self, detailed: bool = False) -> None:
        """Print a formatted summary of the parsing and categorization results."""
        summary = self.generate_summary()
        
        print("\n" + "="*70)
        print("QFX PARSING AND CATEGORIZATION SUMMARY")
        print("="*70)
        
        # File info
        print(f"QFX File: {summary['file_info']['qfx_file']}")
        print(f"Rules File: {summary['file_info']['rules_file']}")
        print(f"Parsed At: {summary['file_info']['parsed_at']}")
        
        # Transaction counts
        counts = summary['transaction_counts']
        print(f"\nTransaction Counts:")
        print(f"  Total transactions: {counts['total']}")
        print(f"  Categorized: {counts['categorized']} ({counts['categorized']/counts['total']*100:.1f}%)")
        print(f"  Low confidence: {counts['low_confidence']} ({counts['low_confidence']/counts['total']*100:.1f}%)")
        print(f"  Uncategorized: {counts['uncategorized']} ({counts['uncategorized']/counts['total']*100:.1f}%)")
        
        # Financial summary
        financial = summary['financial_summary']
        print(f"\nFinancial Summary:")
        print(f"  Total amount: ${financial['total_amount']:.2f}")
        print(f"  Average transaction: ${financial['average_transaction']:.2f}")
        if financial['date_range']['start']:
            print(f"  Date range: {financial['date_range']['start']} to {financial['date_range']['end']}")
        
        # Category breakdown
        if summary['category_breakdown']:
            print(f"\nTop Categories:")
            sorted_categories = sorted(summary['category_breakdown'].items(), 
                                     key=lambda x: abs(x[1]['amount']), reverse=True)
            for category, data in sorted_categories[:10]:
                print(f"  {category}: {data['count']} transactions, ${data['amount']:.2f}, "
                      f"avg confidence: {data['avg_confidence']:.1%}")
        
        # Needs attention
        needs_attention = summary['needs_attention']
        if needs_attention['uncategorized_merchants']:
            print(f"\nTop Uncategorized Merchants (need new rules):")
            for merchant, count in list(needs_attention['uncategorized_merchants'].items())[:5]:
                print(f"  {merchant}: {count} transactions")
        
        if detailed:
            self._print_detailed_summary()
    
    def _print_detailed_summary(self) -> None:
        """Print detailed transaction listings using tabulate for nice formatting."""
        print("\n" + "-"*80)
        print("DETAILED TRANSACTION BREAKDOWN")
        print("-"*80)
        
        # Categorized transactions table
        if self.categorized_transactions:
            print(f"\nCategorized Transactions ({len(self.categorized_transactions)}):")
            headers = ["Date", "Amount", "Confidence", "Category", "Rule Type", "Description"]
            table_data = []
            
            for trans in self.categorized_transactions:
                # Truncate long category names and descriptions for better table formatting
                category = trans.get('predicted_category', 'Unknown')
                if len(category) > 35:
                    category = category[:32] + "..."
                
                description = trans['description']
                if len(description) > 40:
                    description = description[:37] + "..."
                
                table_data.append([
                    trans['date'],
                    f"${trans['amount']:.2f}",
                    f"{trans.get('confidence', 0):.1%}",
                    category,
                    trans.get('rule_type', 'Unknown'),
                    description
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid", maxcolwidths=[10, 10, 8, 35, 12, 40]))
        
        # Low confidence transactions table
        if self.low_confidence_transactions:
            print(f"\nLow Confidence Transactions ({len(self.low_confidence_transactions)}):")
            headers = ["Date", "Amount", "Confidence", "Category", "Rule Type", "Description"]
            table_data = []
            
            for trans in self.low_confidence_transactions:
                category = trans.get('predicted_category', 'Unknown')
                if len(category) > 35:
                    category = category[:32] + "..."
                
                description = trans['description']
                if len(description) > 40:
                    description = description[:37] + "..."
                
                table_data.append([
                    trans['date'],
                    f"${trans['amount']:.2f}",
                    f"{trans.get('confidence', 0):.1%}",
                    category,
                    trans.get('rule_type', 'Unknown'),
                    description
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid", maxcolwidths=[10, 10, 8, 35, 12, 40]))
        
        # Uncategorized transactions table
        if self.uncategorized_transactions:
            print(f"\nUncategorized Transactions ({len(self.uncategorized_transactions)}):")
            headers = ["Date", "Amount", "Extracted Merchant", "Full Description"]
            table_data = []
            
            for trans in self.uncategorized_transactions:
                merchant = self.extract_merchant_name(trans['description'])
                if len(merchant) > 25:
                    merchant = merchant[:22] + "..."
                
                description = trans['description']
                if len(description) > 50:
                    description = description[:47] + "..."
                
                table_data.append([
                    trans['date'],
                    f"${trans['amount']:.2f}",
                    merchant,
                    description
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid", maxcolwidths=[10, 10, 25, 50]))
        
        # Summary statistics table
        print(f"\nSummary Statistics:")
        summary_data = [
            ["Total Transactions", len(self.transactions)],
            ["Categorized", f"{len(self.categorized_transactions)} ({len(self.categorized_transactions)/len(self.transactions)*100:.1f}%)"],
            ["Low Confidence", f"{len(self.low_confidence_transactions)} ({len(self.low_confidence_transactions)/len(self.transactions)*100:.1f}%)"],
            ["Uncategorized", f"{len(self.uncategorized_transactions)} ({len(self.uncategorized_transactions)/len(self.transactions)*100:.1f}%)"],
        ]
        
        if self.categorized_transactions + self.low_confidence_transactions:
            avg_confidence = sum(t.get('confidence', 0) for t in self.categorized_transactions + self.low_confidence_transactions) / \
                           len(self.categorized_transactions + self.low_confidence_transactions)
            summary_data.append(["Average Confidence", f"{avg_confidence:.1%}"])
        
        print(tabulate(summary_data, headers=["Metric", "Value"], tablefmt="simple"))
    
    def save_results(self, output_file: str = None) -> None:
        """Save categorization results to a JSON file."""
        if not output_file:
            # Generate default filename based on QFX file
            qfx_name = Path(self.qfx_file_path).stem
            output_file = f"{qfx_name}_categorized.json"
        
        summary = self.generate_summary()
        
        results = {
            'summary': summary,
            'categorized_transactions': self.categorized_transactions,
            'low_confidence_transactions': self.low_confidence_transactions,
            'uncategorized_transactions': self.uncategorized_transactions
        }
        
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nResults saved to: {output_file}")
    
    def suggest_new_rules(self) -> List[Dict]:
        """Suggest new rules based on uncategorized transactions."""
        suggestions = []
        
        if not self.uncategorized_transactions:
            return suggestions
        
        # Group by merchant
        merchant_groups = defaultdict(list)
        for trans in self.uncategorized_transactions:
            merchant = self.extract_merchant_name(trans['description'])
            if merchant and len(merchant) > 2:
                merchant_groups[merchant].append(trans)
        
        # Suggest rules for merchants with multiple transactions
        for merchant, transactions in merchant_groups.items():
            if len(transactions) >= 2:  # At least 2 transactions
                suggestion = {
                    'type': 'merchant_name',
                    'pattern': merchant,
                    'suggested_category': 'NEEDS_MANUAL_CATEGORIZATION',
                    'transaction_count': len(transactions),
                    'total_amount': sum(t['amount'] for t in transactions),
                    'example_descriptions': [t['description'] for t in transactions[:3]],
                    'date_range': {
                        'start': min(t['date'] for t in transactions if t['date']),
                        'end': max(t['date'] for t in transactions if t['date'])
                    }
                }
                suggestions.append(suggestion)
        
        # Sort by transaction count
        suggestions.sort(key=lambda x: x['transaction_count'], reverse=True)
        return suggestions


def main():
    parser = argparse.ArgumentParser(
        description="Parse QFX files and categorize transactions using existing rules",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Parse QFX file using default rules
  python qfx_parser.py transactions.qfx
  
  # Parse with specific rules file
  python qfx_parser.py transactions.qfx --rules my_rules.json
  
  # Parse and save detailed results
  python qfx_parser.py transactions.qfx --output results.json --detailed
  
  # Use lower confidence threshold
  python qfx_parser.py transactions.qfx --confidence 0.2
        """
    )
    
    parser.add_argument('qfx_file', help='Path to QFX file to parse')
    parser.add_argument('--rules', '-r', default='categorization_rules.json',
                       help='Path to categorization rules JSON file (default: categorization_rules.json)')
    parser.add_argument('--output', '-o', help='Output file for categorized results (JSON format)')
    parser.add_argument('--confidence', '-c', type=float, default=0.3,
                       help='Confidence threshold for categorization (default: 0.3)')
    parser.add_argument('--detailed', '-d', action='store_true',
                       help='Show detailed transaction listings')
    parser.add_argument('--suggest-rules', '-s', action='store_true',
                       help='Suggest new rules for uncategorized transactions')
    
    args = parser.parse_args()
    
    # Validate inputs
    if not Path(args.qfx_file).exists():
        print(f"Error: QFX file not found: {args.qfx_file}")
        sys.exit(1)
    
    # Initialize parser
    qfx_parser = QFXParser(args.qfx_file, args.rules)
    
    # Load rules
    if not qfx_parser.load_rules():
        print("Warning: Proceeding without categorization rules.")
    
    # Parse QFX file
    if not qfx_parser.parse_qfx_file():
        print("Failed to parse QFX file.")
        sys.exit(1)
    
    # Normalize transaction descriptions.
    qfx_parser.normalize()
    IPython.embed()
    
if __name__ == "__main__":
    main()
